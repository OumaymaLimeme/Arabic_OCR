{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7409735,"sourceType":"datasetVersion","datasetId":4309687},{"sourceId":7409740,"sourceType":"datasetVersion","datasetId":4309690},{"sourceId":7409824,"sourceType":"datasetVersion","datasetId":4309745},{"sourceId":7409833,"sourceType":"datasetVersion","datasetId":4309753}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Install Tesseract OCR and required libraries\n\n!pip install pydotplus\n!pip install pytesseract\n!pip install gTTS\n!pip install PyPDF2\n!pip install PyMuPDF\n!pip install pytesseract\n!apt-get install -y poppler-utils\n!apt-get install -y tesseract-ocr\n!apt-get install -y  libtesseract-dev\n!pip install tesseract\n!pip install pytesseract\n!pip install pytesseract pdf2image\n!pip install scikit-learn\n!pip install pymupdf\n!apt-get update\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-15T22:47:37.226281Z","iopub.execute_input":"2024-01-15T22:47:37.226673Z","iopub.status.idle":"2024-01-15T22:51:05.595582Z","shell.execute_reply.started":"2024-01-15T22:47:37.226638Z","shell.execute_reply":"2024-01-15T22:51:05.594410Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pydotplus\n  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyparsing>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from pydotplus) (3.0.9)\nBuilding wheels for collected packages: pydotplus\n  Building wheel for pydotplus (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24552 sha256=bb0734d4f21b14c4846eef89533f502135b5e73f4c93f8c056f7c4d14643b873\n  Stored in directory: /root/.cache/pip/wheels/69/b2/67/08f0eef649af92df772c09f451558298e07fab1bc7cdf33db0\nSuccessfully built pydotplus\nInstalling collected packages: pydotplus\nSuccessfully installed pydotplus-2.0.2\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.10)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\nCollecting gTTS\n  Obtaining dependency information for gTTS from https://files.pythonhosted.org/packages/6a/4f/b133719e7638ca68f8805dd75731371db8d5ed23be84d6fc30845a46bedb/gTTS-2.5.0-py3-none-any.whl.metadata\n  Downloading gTTS-2.5.0-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from gTTS) (2.31.0)\nRequirement already satisfied: click<8.2,>=7.1 in /opt/conda/lib/python3.10/site-packages (from gTTS) (8.1.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (2023.11.17)\nDownloading gTTS-2.5.0-py3-none-any.whl (29 kB)\nInstalling collected packages: gTTS\nSuccessfully installed gTTS-2.5.0\nCollecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nCollecting PyMuPDF\n  Obtaining dependency information for PyMuPDF from https://files.pythonhosted.org/packages/e0/06/7e517c9e81e53bdb53b49ccb1cc31d007db39ad2c62678b83ad0404392f2/PyMuPDF-1.23.14-cp310-none-manylinux2014_x86_64.whl.metadata\n  Downloading PyMuPDF-1.23.14-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting PyMuPDFb==1.23.9 (from PyMuPDF)\n  Obtaining dependency information for PyMuPDFb==1.23.9 from https://files.pythonhosted.org/packages/28/32/6f584a18406f12249c87fc05a2db7d5ad1b5e241bc8dd45e04599ee9eec1/PyMuPDFb-1.23.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n  Downloading PyMuPDFb-1.23.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nDownloading PyMuPDF-1.23.14-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading PyMuPDFb-1.23.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\nSuccessfully installed PyMuPDF-1.23.14 PyMuPDFb-1.23.9\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.10)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libpoppler97 poppler-data\nSuggested packages:\n  ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n  fonts-arphic-uming fonts-nanum\nThe following NEW packages will be installed:\n  libpoppler97 poppler-data poppler-utils\n0 upgraded, 3 newly installed, 0 to remove and 73 not upgraded.\nNeed to get 2564 kB of archives.\nAfter this operation, 16.8 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 poppler-data all 0.4.9-2 [1475 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpoppler97 amd64 0.86.1-0ubuntu1.4 [916 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.4 [174 kB]\nFetched 2564 kB in 2s (1117 kB/s)  \nSelecting previously unselected package poppler-data.\n(Reading database ... 108782 files and directories currently installed.)\nPreparing to unpack .../poppler-data_0.4.9-2_all.deb ...\nUnpacking poppler-data (0.4.9-2) ...\nSelecting previously unselected package libpoppler97:amd64.\nPreparing to unpack .../libpoppler97_0.86.1-0ubuntu1.4_amd64.deb ...\nUnpacking libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\nSelecting previously unselected package poppler-utils.\nPreparing to unpack .../poppler-utils_0.86.1-0ubuntu1.4_amd64.deb ...\nUnpacking poppler-utils (0.86.1-0ubuntu1.4) ...\nSetting up libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\nSetting up poppler-data (0.4.9-2) ...\nSetting up poppler-utils (0.86.1-0ubuntu1.4) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for fontconfig (2.13.1-2ubuntu3) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2build2).\n0 upgraded, 0 newly installed, 0 to remove and 73 not upgraded.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libarchive-dev libleptonica-dev\nThe following NEW packages will be installed:\n  libarchive-dev libleptonica-dev libtesseract-dev\n0 upgraded, 3 newly installed, 0 to remove and 73 not upgraded.\nNeed to get 3343 kB of archives.\nAfter this operation, 15.7 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libarchive-dev amd64 3.4.0-2ubuntu1.2 [491 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libleptonica-dev amd64 1.79.0-1 [1389 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libtesseract-dev amd64 4.1.1-2build2 [1463 kB]\nFetched 3343 kB in 2s (1367 kB/s)          \nSelecting previously unselected package libarchive-dev:amd64.\n(Reading database ... 109336 files and directories currently installed.)\nPreparing to unpack .../libarchive-dev_3.4.0-2ubuntu1.2_amd64.deb ...\nUnpacking libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\nSelecting previously unselected package libleptonica-dev:amd64.\nPreparing to unpack .../libleptonica-dev_1.79.0-1_amd64.deb ...\nUnpacking libleptonica-dev:amd64 (1.79.0-1) ...\nSelecting previously unselected package libtesseract-dev:amd64.\nPreparing to unpack .../libtesseract-dev_4.1.1-2build2_amd64.deb ...\nUnpacking libtesseract-dev:amd64 (4.1.1-2build2) ...\nSetting up libleptonica-dev:amd64 (1.79.0-1) ...\nSetting up libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\nSetting up libtesseract-dev:amd64 (4.1.1-2build2) ...\nProcessing triggers for man-db (2.9.1-1) ...\nCollecting tesseract\n  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: tesseract\n  Building wheel for tesseract (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562550 sha256=276d735bca675850f7a2a1cf411570950fcc0ad56a87b6466c48380a5bddc902\n  Stored in directory: /root/.cache/pip/wheels/71/c9/aa/698c579693e83fdda9ad6d6f0d8f61ed986e27925ef576f109\nSuccessfully built tesseract\nInstalling collected packages: tesseract\nSuccessfully installed tesseract-0.1.3\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.10)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.10)\nRequirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: pymupdf in /opt/conda/lib/python3.10/site-packages (1.23.14)\nRequirement already satisfied: PyMuPDFb==1.23.9 in /opt/conda/lib/python3.10/site-packages (from pymupdf) (1.23.9)\nGet:1 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\nGet:2 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1301 B]    \nGet:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]      \nHit:4 http://archive.ubuntu.com/ubuntu focal InRelease   \nGet:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\nGet:6 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3290 kB]\nHit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\nGet:8 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1450 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3770 kB]\nGet:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3142 kB]\nGet:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1156 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [3292 kB]\nFetched 16.3 MB in 4s (4384 kB/s)                                              \nReading package lists... Done\n","output_type":"stream"}]},{"cell_type":"code","source":"import pydotplus\nfrom IPython.display import display, Image\nimport matplotlib.pyplot as plt\nimport pytesseract\nfrom gtts import gTTS\nimport IPython.display as ipd\nfrom requests import get  # to make GET request","metadata":{"execution":{"iopub.status.busy":"2024-01-15T22:51:05.598050Z","iopub.execute_input":"2024-01-15T22:51:05.598577Z","iopub.status.idle":"2024-01-15T22:51:06.131689Z","shell.execute_reply.started":"2024-01-15T22:51:05.598535Z","shell.execute_reply":"2024-01-15T22:51:06.130570Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## dowenload arabic traineddata\ndef download(url, file_name):\n    # open in binary mode\n    with open(file_name, \"wb\") as file:\n        # get request\n        response = get(url)\n        # write to file\n        file.write(response.content)\n\ndownload(\"https://github.com/tesseract-ocr/tessdata/raw/master/ara.traineddata\",\"ara.traineddata\")","metadata":{"execution":{"iopub.status.busy":"2024-01-15T22:51:06.132995Z","iopub.execute_input":"2024-01-15T22:51:06.133474Z","iopub.status.idle":"2024-01-15T22:51:06.752177Z","shell.execute_reply.started":"2024-01-15T22:51:06.133443Z","shell.execute_reply":"2024-01-15T22:51:06.751011Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## chage traineddata path from environment variables TESSDATA_PREFIX\nimport os\nos.environ['TESSDATA_PREFIX'] = '.'","metadata":{"execution":{"iopub.status.busy":"2024-01-15T22:51:06.754702Z","iopub.execute_input":"2024-01-15T22:51:06.755157Z","iopub.status.idle":"2024-01-15T22:51:06.760911Z","shell.execute_reply.started":"2024-01-15T22:51:06.755120Z","shell.execute_reply":"2024-01-15T22:51:06.759399Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import PyPDF2\nimport pytesseract\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Replace 'your_pdf.pdf' with the actual name of your PDF file\npdf_filename = \"/kaggle/input/education-dataset/education-objective.pdf\"\n\n# Function to extract text from PDF using PyPDF2\ndef extract_text_from_pdf(pdf_filename):\n    with open(pdf_filename, 'rb') as file:\n        pdf_reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page_number in range(len(pdf_reader.pages)):\n            page = pdf_reader.pages[page_number]\n            text += page.extract_text()\n    return text\n\n# Read text from the PDF\npdf_text = extract_text_from_pdf(pdf_filename)\n\n# Check if there is text\nif pdf_text:\n    print(\"Text extracted from PDF:\")\n    print(pdf_text)\nelse:\n    print(f\"No text found in the PDF: {pdf_filename}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T23:23:42.722333Z","iopub.execute_input":"2024-01-15T23:23:42.722734Z","iopub.status.idle":"2024-01-15T23:23:42.935148Z","shell.execute_reply.started":"2024-01-15T23:23:42.722702Z","shell.execute_reply":"2024-01-15T23:23:42.933419Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Text extracted from PDF:\nأھداف\nاﻟﺗﻌﻠﯾم\nأﺷﺎر\nﺗﺷﯾﻣوﻣﺑو\nإﻟﻰ\nدور\nاﻟﺗﻌﻠﯾم\nﻛﺄداة\nﺻﻧﺎﻋﺔ\nﻗرار\nﻗﺎدرة\nﻋﻠﻰ\nﻏرس\nاﻟﺗﻐﯾﯾر\nاﻻﺟﺗﻣﺎﻋﻲ\nواﻟﺗﻘدم\nاﻻﻗﺗﺻﺎدي\nﻓﻲ\nاﻟﺑﻠدان\nاﻟﻧﺎﻣﯾﺔ\nﻣن\nﺧﻼل\nإﻋطﺎء\nاﻟﻣﺟﺗﻣﻌﺎت\nاﻟﻔرﺻﺔ\nﻟﻠﺳﯾطرة\nﻋﻠﻰ\nﻣﺻﺎﺋرھﺎ.\nﺗدﻋو\nﺧطﺔ\nاﻟﺗﻧﻣﯾﺔ\nاﻟﻣﺳﺗداﻣﺔ\nﻟﻌﺎم\n2030\n،\nواﻟﺗﻲ\nاﻋﺗﻣدﺗﮭﺎ\nاﻟﺟﻣﻌﯾﺔ\nاﻟﻌﺎﻣﺔ\nﻟﻸﻣم\nاﻟﻣﺗﺣدة\nﻓﻲ\nﺳﺑﺗﻣﺑر\n2015\n،\nإﻟﻰ\nرؤﯾﺔ\nﺟدﯾدة\nﻟﻣﻌﺎﻟﺟﺔ\nاﻟﺷؤون\nاﻟﺑﯾﺋﯾﺔ\nواﻻﺟﺗﻣﺎﻋﯾﺔ\nواﻻﻗﺗﺻﺎدﯾﺔ\nاﻟﺗﻲ\nﺗواﺟﮫ\nاﻟﻌﺎﻟم\nاﻟﯾوم.\nﺗﺗﺿﻣن\nاﻷﺟﻧدة\n17\nھدﻓًﺎ\nﻣن\nأھداف\nاﻟﺗﻧﻣﯾﺔ\nاﻟﻣﺳﺗداﻣﺔ\n)\nSDGs\n(،\nﺑﻣﺎ\nﻓﻲ\nذﻟك\nھدف\nاﻟﺗﻧﻣﯾﺔ\nاﻟﻣﺳﺗداﻣﺔ\nاﻟراﺑﻊ\nاﻟﻣﺗﻌﻠق\nﺑﺎﻟﺗﻌﻠﯾم.\n]\n1\n[\n]\n2\n[\n]\n3\n[\nﻣﻧذ\nﻋﺎم\n1909\nازدادت\nﻧﺳﺑﺔ\nاﻷطﻔﺎل\nاﻟﻣﻠﺗﺣﻘﯾن\nﺑﺎﻟﻣدارس\nﻓﻲ\nاﻟﻌﺎﻟم\nاﻟﻧﺎﻣﻲ.\nوﻗﺑل\nذﻟك\nاﻟﺗﺣﻘت\nأﻗﻠﯾﺔ\nﺻﻐﯾرة\nﻣن\nاﻷوﻻد\nﺑﺎﻟﻣدرﺳﺔ.\nوﺑﺣﻠول\nﺑداﯾﺔ\nاﻟﻘرن\nاﻟﺣﺎدي\nواﻟﻌﺷرﯾن،\nاﻟﺗﺣق\nﻏﺎﻟﺑﯾﺔ\nاﻷطﻔﺎل\nﻓﻲ\nﻣﻌظم\nﻣﻧﺎطق\nاﻟﻌﺎﻟم\nﺑﺎﻟﻣدرﺳﺔ.\nاﻟﺗﻌﻠﯾم\nاﻻﺑﺗداﺋﻲ\nاﻟﺷﺎﻣل\nھو\nواﺣد\nﻣن\nﺛﻣﺎﻧﻲ\nأھداف\nإﻧﻣﺎﺋﯾﺔ\nأﻟﻔﯾﺔ\nﻋﺎﻟﻣﯾﺔ،\nواﻟﺗﻲ\nأُﺣرِز\nﺗﻘدم\nﻧﺣوھﺎ\nﻓﻲ\nاﻟﻌﻘد\nاﻟﻣﺎﺿﻲ\nﻟﻛن\nﺑﻘﻲ\nھﻧﺎك\nﻋواﺋق\nﻓﻲ\nھذا\nاﻟﻣﺟﺎل.\nﯾُﻌد\nﺗﺄﻣﯾن\nاﻟﺗﻣوﯾل\nاﻟﺧﯾري\nﻣن\nاﻟﻣﺎﻧﺣﯾن\nاﻟﻣﺣﺗﻣﻠﯾن\nأﺣد\nاﻟﻣﺷﻛﻼت\nاﻟﻣﺳﺗﻣرة\nﺑﺷﻛل\nﺧﺎص.\nأﺷﺎر\nاﻟﺑﺎﺣﺛون\nﻓﻲ\nﻣﻌﮭد\nﺗﻧﻣﯾﺔ\nﻣﺎ\nوراء\nاﻟﺑﺣﺎر\n)أو\nدي\nآي(\nإﻟﻰ\nأن\nاﻟﻌﻘﺑﺎت\nاﻟرﺋﯾﺳﯾﺔ\nأﻣﺎم\nﺗﻣوﯾل\nاﻟﺗﻌﻠﯾم\nﺗﺷﻣل\nﺗﺿﺎرب\nأوﻟوﯾﺎت\nاﻟﻣﺎﻧﺣﯾن\nوھﯾﻛﻠﯾﺔ\nاﻟﻣﺳﺎﻋدات\nﻏﯾر\nاﻟﻧﺎﺿﺟﺔ\nواﻻﻓﺗﻘﺎر\nإﻟﻰ\nاﻷدﻟﺔ\nواﻟﻣﻧﺎﺻرة\nﻟﮭذه\nاﻟﻘﺿﯾﺔ.\nﺑﺎﻹﺿﺎﻓﺔ\nإﻟﻰ\nذﻟك،\nﺣددت\nﻣﻧظﻣﺔ\nاﻟﺷﻔﺎﻓﯾﺔ\nاﻟدوﻟﯾﺔ\nاﻟﻔﺳﺎد\nﻓﻲ\nﻗطﺎع\nاﻟﺗﻌﻠﯾم\nﺑﺎﻋﺗﺑﺎره\nﺣﺟر\nﻋﺛرة\nأﻣﺎم\nﺗﺣﻘﯾق\nاﻟﺗﻌﻠﯾم\nاﻻﺑﺗداﺋﻲ\nاﻟﺷﺎﻣل\nﻓﻲ\nأﻓرﯾﻘﯾﺎ.\nﻋﻼوة\nﻋﻠﻰ\nذﻟك،\nﻓﺈن\nاﻟطﻠب\nﻓﻲ\nاﻟﻌﺎﻟم\nاﻟﻧﺎﻣﻲ\nﻋﻠﻰ\nﺗﺣﺳﯾن\nاﻟوﺻول\nإﻟﻰ\nاﻟﺗﻌﻠﯾم\nﻟﯾس\nﻣرﺗﻔﻌًﺎ\nﻛﻣﺎ\nﺗوﻗﻊ\nاﻷﺟﺎﻧب.\nﺗﺗردد\nاﻟﺣﻛوﻣﺎت\nاﻷﺻﻠﯾﺔ\nﻓﻲ\nﺗﺣﻣّل\nاﻟﺗﻛﺎﻟﯾف\nاﻟﻣﺳﺗﻣرة\nاﻟﻣﻌﻧﯾﺔ\nﺑﺎﻟﺗﻌﻠﯾم.\nھﻧﺎك\nأﯾﺿًﺎ\nﺿﻐوط\nاﻗﺗﺻﺎدﯾﺔ\nﻣن\nﺑﻌض\nاﻵﺑﺎء\nواﻷﻣﮭﺎت،\nاﻟذﯾن\nﯾﻔﺿﻠون\nأن\nﯾﻛﺳب\nأطﻔﺎﻟﮭم\nاﻟﻣﺎل\nﻋﻠﻰ\nاﻟﻣدى\nاﻟﻘﺻﯾرﺑدﻻً\nﻣن\nاﻟﻌﻣل\nﻣن\nأﺟل\nﺗﺣﻘﯾق\nﻓواﺋد\nاﻟﺗﻌﻠﯾم\nﻋﻠﻰ\nاﻟﻣدى\nاﻟطوﯾل.\n]\n4\n[\n]\n5\n[\nﺗُﺷﯾر\nدراﺳﺔ\nأﺟراھﺎ\nﻣﻌﮭد\nاﻟﯾوﻧﺳﻛو\nاﻟدوﻟﻲ\nﻟﻠﺗﺧطﯾط\nاﻟﺗرﺑوي\nإﻟﻰ\nأن\nوﺟود\nﻗدرات\nأﻗوى\nﻓﻲ\nاﻟﺗﺧطﯾط\nواﻹدارة\nاﻟﺗرﺑوﯾﯾن\nﻗد\nﯾﻛون\nﻟﮫ\nﺗﺄﺛﯾر\nاﻣﺗدادي\nھﺎم\nﻋﻠﻰ\nاﻟﻧظﺎم\nﻛﻛل.\nﺗﺗطﻠب\nﺗﻧﻣﯾﺔ\nاﻟﻘدرات\nاﻟﻣﺳﺗداﻣﺔ\nﺗدﺧﻼت\nﻣﻌﻘدة\nﻋﻠﻰ\nاﻟﻣﺳﺗوﯾﺎت\nاﻟﻣؤﺳﺳﯾﺔ\nواﻟﺗﻧظﯾﻣﯾﺔ\nواﻟﻔردﯾﺔ\nواﻟﺗﻲ\nﯾﻣﻛن\nأن\nﺗﺳﺗﻧد\nإﻟﻰ\nﺑﻌض\nاﻟﻣﺑﺎدئ\nاﻷﺳﺎﺳﯾﺔ:\n]\n6\n[\n●\nﯾﺟب\nأن\nﺗﻛون\nاﻟﻘﯾﺎدة\nواﻟﻣﻠﻛﯾﺔ\nاﻟوطﻧﯾﺔ\nﻣﻌﯾﺎرًا\nﻷي\nﺗدﺧل؛\n●\nﯾﺟب\nأن\nﺗﻛون\nاﻻﺳﺗراﺗﯾﺟﯾﺎت\nذات\nﺻﻠﺔ\nﺑﺎﻟﺳﯾﺎق\nوﻣﺣددة\nاﻟﺳﯾﺎق؛\n●\nﯾﺟب\nأن\nﺗﺳﺗﺧدم\nاﻟﺧطط\nﻣﺟﻣوﻋﺔ\nﻣﺗﻛﺎﻣﻠﺔ\nﻣن\nاﻟﺗدﺧﻼت\nاﻟﻣﻛﻣّﻠﺔ،\nرﻏم\nأن\nاﻟﺗﻧﻔﯾذ\nﯾﻣﻛن\nأن\nﯾﺗﻘدم\nﻋﻠﻰ\nﺷﻛل\nﺧطوات؛\n●\nﯾﺟب\nﻋﻠﻰ\nاﻟﺷرﻛﺎء\nاﻻﻟﺗزام\nﺑﺎﺳﺗﺛﻣﺎر\nطوﯾل\nاﻷﺟل\nﻓﻲ\nﺗﻧﻣﯾﺔ\nاﻟﻘدرات\nﻣﻊ\nاﻟﻌﻣل\nﻋﻠﻰ\nﺗﺣﻘﯾق\nﺑﻌض\nاﻹﻧﺟﺎزات\nﻗﺻﯾرة\nاﻷﺟل؛\n●\nﯾﺟب\nأن\nﯾﻛون\nاﻟﺗدﺧل\nاﻟﺧﺎرﺟﻲ\nﻣﺷروطًﺎ\nﺑﺗﻘﯾﯾم\nﺗﺄﺛﯾر\nاﻟﻘدرات\nاﻟوطﻧﯾﺔ\nﻋﻠﻰ\nﻣﺧﺗﻠف\nاﻟﻣﺳﺗوﯾﺎت؛\n●\nﯾﺟب\nﻋزل\nﻧﺳﺑﺔ\nﻣﻌﯾﻧﺔ\nﻣن\nاﻟطﻼب\nﻟﺗﺗﻠﻘﻰ\nﺗﻌﻠﯾﻣًﺎ\nﻣﺑﺗﻛرًا\nﻣن\nﻗﺑل\nاﻷﻛﺎدﯾﻣﯾﯾن)ﻋﺎدةً\nﻣﺎ\nﯾُﻣﺎرس\nذﻟك\nﻓﻲ\nاﻟﻣدارس\nﺑﻌد\nاﻟﺻف\nاﻟﻌﺎﺷر(.\n","output_type":"stream"}]},{"cell_type":"code","source":"import urllib.request\narabic_data_url = \"https://github.com/tesseract-ocr/tessdata/raw/main/ara.traineddata\"\nurllib.request.urlretrieve(arabic_data_url, \"/kaggle/working/ara.traineddata\")\nimport os\nos.environ[\"TESSDATA_PREFIX\"] = \"/kaggle/working/\"\nimport pytesseract\nfrom PIL import Image\nfrom pdf2image import convert_from_path\nimport urllib.request\nimport os\n# Set the path to the Tesseract executable\npytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n\n# Download Arabic language data\narabic_data_url = \"https://github.com/tesseract-ocr/tessdata/raw/main/ara.traineddata\"\nurllib.request.urlretrieve(arabic_data_url, \"/kaggle/working/ara.traineddata\")\n\n# Set TESSDATA_PREFIX\nos.environ[\"TESSDATA_PREFIX\"] = \"/kaggle/working/\"\n\n# Replace 'your_pdf.pdf' with the actual name of your PDF file\npdf_filename = \"/kaggle/input/other-dataset/economie tunisienne-histoire.pdf\"\n\n# Convert PDF pages to images\nimages = convert_from_path(pdf_filename, 500)  # 500 is the DPI (adjust as needed)\n\n# Iterate through each image and perform OCR\nfor i, image in enumerate(images):\n    # Save the image\n    image_path = f\"/kaggle/working/image_{i+1}.png\"\n    image.save(image_path, \"PNG\")\n    # Perform OCR on the image with the 'ara' language\n    arabic_text = pytesseract.image_to_string(image_path, lang='ara', config=\"--psm 6\")\n    # Print or use the extracted text as needed\n    print(f\"Text from Image {i + 1}:\\n{arabic_text}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T23:26:25.811653Z","iopub.execute_input":"2024-01-15T23:26:25.812081Z","iopub.status.idle":"2024-01-15T23:26:41.693461Z","shell.execute_reply.started":"2024-01-15T23:26:25.812051Z","shell.execute_reply":"2024-01-15T23:26:41.692608Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Text from Image 1:\n5 * مي ‎ »*‏ * . ل خص: خصة ف تونس\nتاريخ اقتصاد دودس ([عدل] 5 يِِ\n\n‎٠‏ بورصة تونس\nالتأميم (1961-1956) [عل] عدل\nبُعيد الاستقلال؛ كان الهم الشاغل للحكومة التونسية يتمثل في تحرير الاقتصاد من مخلفات الاستعمار الفرنسي\nوالذي شجّع الفلاحة والاستخراج المنجمي مع إهمال تام للصناعة. وفي الفترة مابين سنة 6 و 1960 غادر أغلب الموظفين الفرنسبين وقَدّرِ\nعددهم آنذاك ب 12000 الإدارة التونسية عائدين إلى فرنسا. ولتأكيد سيطرة الدولة على القطاعات الأساسية أسست الحكومة الشركة الوطنية للسكك\nالحديدية سئة 1956؛ وأمّمت القطاع المصرفي وشركات الكهرباء والغاز والماء. ثم أممت شركات النقل وشاركت ب 9650 في رأس مال شركة\nالطيران تونيزار وأسست الشركة التونسية للملاحة. وبالتزامن مع ذلك أصبح الدينار التونسي بموجب القانون الصادر بتاريخ 18 أكتوبر 1958\nالعملة الرسمية للدولة التونسيّة. ولكن كل هذا لا يعكس نزعة اشتراكية بقدر ما يبين حرص الحكومة الناشئة على تعزيز سيطرتها مع اتباع سياسة\nلبرالية قائمة على تشجيع الإستثمار والتجارة الخارجية. ومن أجل ذلك منحت الحكومة امتيازات جبائية وتسهيلات في القروض في الخماسية التي تلت\nالاستقلال لتحفيز مشاركة أكبر للقطاع الخاص.\n\f\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install scikit-learn\n!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-01-15T22:54:02.361288Z","iopub.execute_input":"2024-01-15T22:54:02.361741Z","iopub.status.idle":"2024-01-15T22:54:31.172213Z","shell.execute_reply.started":"2024-01-15T22:54:02.361702Z","shell.execute_reply":"2024-01-15T22:54:31.170846Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.57.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom gensim import corpora, models\nfrom pdf2image import convert_from_path\nimport pytesseract\n\n# Function to extract text from PDF using pdf2image and pytesseract\ndef extract_text_from_pdf(pdf_path):\n    images = convert_from_path(pdf_path, 500)  # Adjust DPI as needed\n    text = [pytesseract.image_to_string(image, lang='ara', config=\"--psm 6\") for image in images]\n    return ' '.join(text)\n\n# Function to predict category for a document\ndef predict_category(pdf_file, lda_model, dictionary):\n    text = extract_text_from_pdf(pdf_file)\n    bow_vector = dictionary.doc2bow(text.split())\n\n    # Get the topic distribution for the document\n    topic_distribution = lda_model[bow_vector]\n\n    # Choose the topic with the highest probability as the predicted category\n    predicted_category = max(topic_distribution, key=lambda x: x[1])[0]\n\n    return predicted_category\n\n# Function to map topic IDs to predefined labels\ndef map_topic_to_label(topic_id):\n    # You should replace the following with your actual labels\n    labels = {\n        0: \"Label1\",\n        1: \"Label2\",\n        2: \"Label3\",\n        3: \"Label4\",\n        4: \"Label5\",\n    }\n    return labels.get(topic_id, \"Unknown\")\n\n# Directory containing initial set of PDF files\ninitial_pdf_directory = \"/kaggle/input/education-dataset\"\ninitial_pdf_files = [os.path.join(initial_pdf_directory, file) for file in os.listdir(initial_pdf_directory) if file.endswith(\".pdf\")]\n\n# Directory containing new PDF files\nnew_pdf_directory = \"/kaggle/input/other-dataset\"\nnew_pdf_files = [os.path.join(new_pdf_directory, file) for file in os.listdir(new_pdf_directory) if file.endswith(\".pdf\")]\n\n# Combine all PDF files\nall_pdf_files = initial_pdf_files + new_pdf_files\n\n# Extract text from each PDF and combine into a single list\nall_text = [extract_text_from_pdf(pdf_file) for pdf_file in all_pdf_files]\n\n# Tokenize the text and remove common words\ntokenized_text = [text.split() for text in all_text]\n\n# Create a dictionary representation of the documents\ndictionary = corpora.Dictionary(tokenized_text)\n\n# Convert the tokenized documents into a bag of words representation\ncorpus = [dictionary.doc2bow(tokens) for tokens in tokenized_text]\n\n# Train the LDA model\nlda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n\n# Print the topics discovered by LDA\nprint(lda_model.print_topics())\n\n# Create a directory to store categorized text files\noutput_directory = \"/kaggle/working/arabic\"\nos.makedirs(output_directory, exist_ok=True)\n\n# Write the predicted categories for each document to separate text files\nfor i, pdf_file in enumerate(all_pdf_files):\n    predicted_category = predict_category(pdf_file, lda_model, dictionary)\n    label = map_topic_to_label(predicted_category)\n\n    # Create a text file for the category and write the extracted text\n    category_file_path = os.path.join(output_directory, f\"{label}_category_{predicted_category}.txt\")\n    with open(category_file_path, 'a', encoding='utf-8') as category_file:\n        category_file.write(f\"Document {i + 1} - {pdf_file}\\n\\n\")\n        category_file.write(f\"Extracted Text:\\n{all_text[i]}\\n\\n\")\n        category_file.write(f\"Predicted Category: {label} (Topic ID: {predicted_category})\\n\\n\")\n        category_file.write(\"=\" * 50 + \"\\n\\n\")\n\nprint(f\"Results saved in the '{output_directory}' directory.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T23:36:49.944040Z","iopub.execute_input":"2024-01-15T23:36:49.944630Z","iopub.status.idle":"2024-01-15T23:39:07.287967Z","shell.execute_reply.started":"2024-01-15T23:36:49.944588Z","shell.execute_reply":"2024-01-15T23:39:07.286758Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[(0, '0.026*\"من\" + 0.013*\"على\" + 0.013*\"الإنسان\" + 0.010*\"التي\" + 0.010*\"الجسم\" + 0.010*\"الطعام\" + 0.007*\"ذلك\" + 0.007*\"الغذائية\" + 0.007*\"غير\" + 0.007*\"سواء\"'), (1, '0.001*\"على\" + 0.001*\"من\" + 0.001*\"في\" + 0.001*\"إلى\" + 0.001*\"التعليم\" + 0.001*\"أن\" + 0.001*\"ذلك\" + 0.001*\"يجب\" + 0.001*\"مع\" + 0.001*\"ما\"'), (2, '0.021*\"في\" + 0.017*\"الاقتصاد\" + 0.013*\"من\" + 0.013*\"على\" + 0.013*\"التونسي\" + 0.009*\"مع\" + 0.009*\"15\" + 0.009*\"الاقتصادي\" + 0.009*\"المنتدى\" + 0.005*\"إلى\"'), (3, '0.023*\"التعليم\" + 0.023*\"أو\" + 0.018*\"عملية\" + 0.010*\"من\" + 0.010*\"أن\" + 0.010*\"يمكن\" + 0.010*\"وضع\" + 0.010*\"علم\" + 0.010*\"نظامي\" + 0.005*\"في\"'), (4, '0.028*\"في\" + 0.022*\"على\" + 0.018*\"من\" + 0.015*\"أن\" + 0.013*\"إلى\" + 0.010*\"التعليم\" + 0.009*\"يجب\" + 0.007*\"ذلك\" + 0.006*\"مع\" + 0.006*\"المستدامة\"')]\nResults saved in the '/kaggle/working/arabic' directory.\n","output_type":"stream"}]}]}